#!/usr/bin/env python
# Encoding required to deal with 'micro' character
"""Script for auto-generating DICOM SR context groups from FHIR JSON value set
resources.


"""

import argparse
from io import BytesIO
import json
from keyword import iskeyword
import ftplib
import logging
import os
from pathlib import Path
import re
from pprint import pprint
import urllib.request as urllib_request
from xml.etree import ElementTree as ET
import zipfile


LOGGER = logging.getLogger(__name__)


PYDICOM_SRC = Path(__file__).parent.parent.parent / "src" / "pydicom"
SR_DIRECTORY = PYDICOM_SRC / "sr"

FTP_HOST = "medical.nema.org"
FTP_PATH = "medical/dicom/resources/valuesets/"
FTP_FHIR_REGEX = re.compile(r".+/DICOM_ValueSets(?P<version>[0-9]{4}[a-z])_release_fhir_json_[0-9]+.zip")
CID_ID_REGEX = re.compile("^dicom-cid-([0-9]+)-[a-zA-Z]+")

P16_TO1_URL = "http://dicom.nema.org/medical/dicom/current/output/chtml/part16/chapter_O.html"
P16_TD1_URL = "http://dicom.nema.org/medical/dicom/current/output/chtml/part16/chapter_D.html"


# Example excerpt fhir JSON for reference
"""
    "resourceType":"ValueSet",
    "id":"dicom-cid-10-InterventionalDrug",
    ...
    "name":"InterventionalDrug",
    ...
    "compose":{
        "include":[
            {
                "system":"http://dicom.nema.org/resources/ontology/DCM",
                "concept":[
                    {
                        "code":"130290",
                        "display":"Median"
                    }
                ]
            },
            {
                "system":"http://snomed.info/sct",
                "concept":[
                    {
                        "code":"387362001",
                        "display":"Epinephrine"
                    },
                ], ...
            }, ...
        ],
"""
# The list of scheme designators is not complete.
# For full list see table 8-1 in part 3.16 chapter 8:
# http://dicom.nema.org/medical/dicom/current/output/chtml/part16/chapter_8.html#table_8-1
FHIR_SYSTEM_TO_DICOM_SCHEME_DESIGNATOR = {
    "http://snomed.info/sct": "SCT",
    "http://dicom.nema.org/resources/ontology/DCM": "DCM",
    "http://loinc.org": "LN",
    "http://www.radlex.org": "RADLEX",
    "http://sig.biostr.washington.edu/projects/fm/AboutFM.html": "FMA",
    "http://www.nlm.nih.gov/mesh/meshhome.html": "MSH",
    "http://ncit.nci.nih.gov": "NCIt",
    "http://unitsofmeasure.org": "UCUM",
    "http://hl7.org/fhir/sid/ndc": "NDC",
    "urn:iso:std:iso:11073:10101": "MDC",
    "doi:10.1016/S0735-1097(99)00126-6": "BARI",
    "http://www.nlm.nih.gov/research/umls": "UMLS",
    "http://pubchem.ncbi.nlm.nih.gov": "PUBCHEM_CID",
    "http://braininfo.rprc.washington.edu/aboutBrainInfo.aspx#NeuroNames": "NEU",
    "http://www.itis.gov": "ITIS_TSN",
    "http://arxiv.org/abs/1612.07003": "IBSI",
    "http://www.nlm.nih.gov/research/umls/rxnorm": "RXNORM",
    "http://hl7.org/fhir/sid/icd-10": "I10",
}

DOC_LINES = [
    f"# Auto-generated by {os.path.basename(__file__)}.\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
]


def camel_case(s):
    leave_alone = (
        "mm",
        "cm",
        "km",
        "um",
        "ms",  #  'us'?-doesn't seem to be there
        "ml",
        "mg",
        "kg",
    )  # ... probably need others
    return "".join(
        word.capitalize() if word != word.upper() and word not in leave_alone else word
        for word in re.split(r"\W", s, flags=re.UNICODE)
        if word.isalnum()
    )


def keyword_from_meaning(name):
    """Return a camel case valid python identifier"""
    # Try to adhere to keyword scheme in DICOM (CP850)

    # singular/plural alternative forms are made plural
    #     e.g., “Physician(s) of Record” becomes “PhysiciansOfRecord”
    print("NAME IS", name)
    kw = name.replace("(s)", "s")

    # “Patient’s Name” -> “PatientName”
    # “Operators’ Name” -> “OperatorsName”
    kw = kw.replace("’s ", " ")
    kw = kw.replace("'s ", " ")
    kw = kw.replace("s’ ", "s ")
    kw = kw.replace("s' ", "s ")

    # Mathematical symbols
    kw = kw.replace("%", " Percent ")
    kw = kw.replace(">", " Greater Than ")
    kw = kw.replace("=", " Equals ")
    kw = kw.replace("<", " Lesser Than ")

    kw = kw.replace("_", " ")

    kw = re.sub(r"([0-9]+)\.([0-9]+)", "\\1 Point \\2", kw)
    kw = re.sub(r"\s([0-9.]+)-([0-9.]+)\s", " \\1 To \\2 ", kw)

    kw = re.sub(r"([0-9]+)day", "\\1 Day", kw)
    kw = re.sub(r"([0-9]+)y", "\\1 Years", kw)

    # Remove category modifiers, such as "(specimen)", "(procedure)",
    # "(body structure)", etc.
    kw = re.sub(r"^(.+) \([a-z ]+\)$", "\\1", kw)

    kw = camel_case(kw.strip())

    # Python variables must not begin with a number.
    if re.match(r"[0-9]", kw):
        kw = "_" + kw

    if kw == "None":
        kw = "None_"

    if not kw.isidentifier() or iskeyword(kw):
        raise ValueError(f"Invalid keyword '{kw}' generated from '{name}'")

    return kw


def setup_logger(debug=False) -> None:
    """Setup the logging."""
    logger = logging.getLogger(__name__)
    # Ensure only have one StreamHandler
    LOGGER.handlers = []
    handler = logging.StreamHandler()
    level = logging.DEBUG if debug else logging.INFO
    LOGGER.setLevel(level)
    formatter = logging.Formatter("%(levelname).1s: %(message)s")
    handler.setFormatter(formatter)
    LOGGER.addHandler(handler)


def download_fhir_value_sets(local_dir: Path) -> None | str:
    """Log into the DICOM FTP server and download the zip file containing the
    FHIR JSON files.

    Parameters
    ----------
    local_dir : pathlib.Path
        The directory where the zip file will be written to, as
        ``local_dir/version/*.zip``.

    Returns
    -------
    str | None
        If the download failed then returns ``None``, otherwise returns the
        DICOM version as :class:`str`.
    """
    LOGGER.debug(f"  Logging into FTP server: {FTP_HOST}")
    ftp = ftplib.FTP(FTP_HOST, timeout=60)
    ftp.login("anonymous")

    version = None

    try:
        LOGGER.debug(f"  Searching contents of '{FTP_PATH}' for JSON ZIP file")
        for remote_path in ftp.nlst(FTP_PATH):
            LOGGER.debug(f"    {remote_path}")
            match = FTP_FHIR_REGEX.match(remote_path)
            if match:
                LOGGER.debug("  Found FHIR JSON ZIP file, downloading...")
                with BytesIO() as fp:
                    ftp.retrbinary(f"RETR {remote_path}", fp.write)
                    data = fp.getvalue()

                version = match.group('version')
                (local_dir / version).mkdir(parents=True, exist_ok=True)
                local_path = local_dir / version / Path(remote_path).name

                LOGGER.debug(f"    Writing data to {local_path}")
                with open(local_path, "wb") as f:
                    f.write(data)

                break
    finally:
        ftp.quit()

    return version


def extract_cid_files(path: Path, version: str, cid_folder="CIDs") -> None:
    """Extract the JSON files in the downloaded ZIP file to ``path / cid_folder``.

    Parameters
    ----------
    path : pathlib.Path
        The base directory.
    version : str
        The name of the version subdirectory containing the ZIP file.
    cid_folder : str, optional
        The name of the subdirectory the CID files will be extracted to, default
        ``CIDs``.
    """
    files = list((path / version).glob("*.zip"))
    if not files:
        raise ValueError(f"No zip files found in {path / version}")

    if len(files) > 1:
        raise ValueError(f"Multiple zip files found in {path / version}")

    # Create the output directory (if it doesn't already exist)
    cid_dir = path / cid_folder
    cid_dir.mkdir(parents=True, exist_ok=True)
    LOGGER.debug(f"  Extracting CID files to {cid_dir}")
    with zipfile.ZipFile(files[0]) as z:
        # Forcibly flatten the ZIP contents into the `cid_folder`
        for zip_path in (Path(x) for x in z.namelist()):
            with open(cid_dir / zip_path.name, 'wb') as f:
                f.write(z.read(str(zip_path)))


def extract_table_data(path: Path, version: str, ext: str = "htm") -> list[bytes]:
    """Extract the table data from the downloaded HTML files.

    Parameters
    ----------
    path : pathlib.Path
        The base directory.
    version : str
        The name of the version subdirectory containing the HTML files.
    ext : str, optional
        The extension of the downloaded HTML files.
    """
    files = list((path / version).glob(f"*.{ext}"))
    if len(files) != 2:
        raise ValueError(
            f"The Part 16, Chapter D and O HTML files were not found in {path / version}"
        )

    # Chapter D
    # <html xmlns="http://www.w3.org/1999/xhtml">
    #    <head>
    #       <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    #       <title>D DICOM Controlled Terminology Definitions (Normative)</title>

    # Chapter O
    # <html xmlns="http://www.w3.org/1999/xhtml">
    #    <head>
    #       <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    #       <title>O SNOMED Concept ID to SNOMED ID Mapping</title>

    data = [None, None]

    for html_file in files:
        with open(html_file, "rb") as f:
            file_data = f.read()
            root = ET.fromstring(file_data, parser=ET.XMLParser(encoding="utf-8"))
            for element in root.iter():
                if element.tag.endswith("title"):
                    title = element.text
                    if title.startswith("D"):
                        data[0] = file_data
                    elif title.startswith("O"):
                        data[1] = file_data

                    break

    if None in data:
        raise ValueError("One or both HTML files do not contain the expected data")

    return data


def _get_text(element) -> str:
    return "".join(element.itertext()).strip()


def get_table_o1(data: bytes) -> list[tuple[str, str, str]]:
    """Return a list of SNOMED-CT to SNOMED RT mappings.

    Returns
    -------
    list[tuple[str, str, str]]
        A list of (SCT, SRT, SNOMED Fully Specified Name) generated from
        Table O-1 in Part 16 of the DICOM Standard.
    """
    LOGGER.info("Download and process SNOMED mappings from Part 16, Table O-1")
    root = ET.fromstring(data, parser=ET.XMLParser(encoding="utf-8"))
    namespaces = {"w3": root.tag.split("}")[0].strip("{")}
    body = root.find("w3:body", namespaces=namespaces)
    table = body.findall(".//w3:tbody", namespaces=namespaces)[0]
    rows = table.findall("./w3:tr", namespaces=namespaces)
    data = []
    for row in rows:
        data.append(
            (
                _get_text(row[0].findall(".//w3:p", namespaces=namespaces)[-1]),
                _get_text(row[1].findall(".//w3:p", namespaces=namespaces)[0]),
                _get_text(row[2].findall(".//w3:p", namespaces=namespaces)[0]),
            )
        )

    return data


def get_table_d1(data: bytes) -> list[tuple[str, str]]:
    """Return a list of DICOM code values to code meaning mappings.

    Returns
    -------
    list[tuple[str, str]]
        A list of (Code Value, Code Meaning) generated from Table D-1 in Part
        16 of the DICOM Standard.
    """
    LOGGER.info("Processing Part 16, Table D-1")
    root = ET.fromstring(data, parser=ET.XMLParser(encoding="utf-8"))
    namespaces = {"w3": root.tag.split("}")[0].strip("{")}
    body = root.find("w3:body", namespaces=namespaces)
    table = body.findall(".//w3:tbody", namespaces=namespaces)[0]
    rows = table.findall("./w3:tr", namespaces=namespaces)
    return [
        (
            _get_text(row[0].findall(".//w3:p", namespaces=namespaces)[0]),
            _get_text(row[1].findall(".//w3:p", namespaces=namespaces)[0]),
        )
        for row in rows
    ]


def write_concepts(
    concepts: dict[str, dict[str, dict[str, tuple[str, list[int]]]]],
    cid_lists: dict[int, dict[str, list[str]]],
    name_for_cid: dict[int, str],
) -> None:
    """Write.

    Parameters
    ----------
    concepts : dict[str, dict[str, dict[str, tuple[str, list[int]]]]]
        A :class:`dict` containing the concept schemes and their contents as
        ``concepts[scheme_designator][keyword] = {code: (display, [cid, ...])}``
    cid_lists : dict[int, dict[str, list[str]]]
        The schemes and code keywords for each CID ID as
    name_for_cid : dict[int, str]
        A :class:`dict:` mapping CID IDs their name.
    """
    # Write the concepts dict
    path = SR_DIRECTORY / "_concepts_dict.py"
    LOGGER.info(f"Writing ... to '{path}'")

    lines = DOC_LINES + [
        "# Dict with scheme designator keys; value format is:\n",
        "#   {keyword: {code1: (meaning, cid_list), code2: ...}\n",
        "#\n",
        "# Most keyword identifiers map to a single code, but not all\n",
        "\n",
    ]

    with open(path, "w", encoding="UTF8") as f:
        f.writelines(lines)
        f.write("concepts = {}\n")  # start with empty dict
        for scheme, value in concepts.items():
            f.write(f"\nconcepts['{scheme}'] = \\\n")
            pprint(value, f)

    # Write the CID dict
    path = SR_DIRECTORY / "_cid_dict.py"
    LOGGER.info(f"Writing ... to '{path}'")

    lines = DOC_LINES + [
        "# Dict with cid number as keys; value format is:\n",
        "#   {scheme designator: <list of keywords for current cid>\n",
        "#    scheme_designator: ...}\n",
        "\n",
    ]

    with open(path, "w", encoding="UTF8") as f:
        f.writelines(lines)
        f.write("name_for_cid = {}\n")
        f.write("cid_concepts = {}\n")
        for cid, value in cid_lists.items():
            f.write(f"\nname_for_cid[{cid}] = '{name_for_cid[cid]}'\n")
            f.write(f"cid_concepts[{cid}] = \\\n")
            pprint(value, f)


def write_snomed_mapping(snomed_codes: list[tuple[str, str, str]]) -> None:
    """Write the SNOMED-CT <-> SNOMED RT mapping dict to ``_snomed_dict.py``."""
    path = SR_DIRECTORY / "_snomed_dict.py"
    LOGGER.info(f"Writing SNOMED-CT to RT mappings to '{path}'")

    with open(path, "w", encoding="UTF8") as f:
        lines = DOC_LINES + [
            "# Dict with scheme designator keys; value format is:\n",
            "#   {concept_id1: snomed_id1, concept_id2: ...}\n",
            "# or\n",
            "#   {snomed_id1: concept_id1, snomed_id2: ...}\n",
            "\n",
        ]

        f.writelines(lines)
        f.write("mapping = {}\n")

        # Write the SCT -> SRT mapping
        f.write("\nmapping['SCT'] = {\n")
        for sct, srt, _ in snomed_codes:
            f.write(f"    '{sct}': '{srt}',\n")

        f.write("}\n")

        # Write the SRT -> SCT mapping
        f.write("\nmapping['SRT'] = {\n")
        for sct, srt, _ in snomed_codes:
            f.write(f"     '{srt}': '{sct}',\n")

        f.write("}")


def setup_argparse():
    parser = argparse.ArgumentParser(
        description=(
            "Update the sr/ code and concepts dictionaries"
        ),
        usage="generate_concept_dicts.py path [options]",
    )

    opts = parser.add_argument_group("Options")
    opts.add_argument(
        "path",
        help="The path to download the JSON CID files to",
        type=str,
    )
    opts.add_argument(
        "--download",
        help="Download the FHIR JSON CID files",
        action="store_true",
    )
    opts.add_argument(
        "--cid-directory",
        help="The name of the directory where the CID should be located",
        type=str,
        default="CIDs",
    )
    opts.add_argument(
        "--version",
        help="The version of the downloaded CID ZIP file",
        type=str,
    )
    opts.add_argument(
        "--debug",
        help="Set logging to debug mode",
        action="store_true",
        default=False,
    )

    return parser.parse_args()


def process_files(cid_directory: Path, snomed_mapping, dicom_mapping) -> None:
    LOGGER.info(f"Processing the CID JSON files in {cid_directory}")

    # Mapping of:
    #   Scheme: Keywords
    #       Keyword: Codes
    #           Code: (Display, CIDs containing the code)
    # concepts[scheme_designator][name] = {code: (display, [cid])}
    concepts: dict[str, dict[str, dict[str, tuple[str, list[int]]]]] = {}

    # The schemes and code keywords for each CID ID
    cid_lists: dict[int, dict[str, list[str]]] = {}

    # Mapping of CID ID to CID name
    name_for_cid: dict[int, str] = {}

    cid_paths = sorted(cid_directory.glob("*.json"), key=lambda x: int(x.name.split("-")[3]))
    for path in cid_paths:
        LOGGER.debug(f"  Processing '{path.name}'")
        with open(path, "rb") as f:
            data = json.loads(f.read())

        cid = int(CID_ID_REGEX.match(data["id"]).group(1))
        # if cid != 12325:
        #     continue

        cid_version = data["version"]
        name_for_cid[cid] = data["name"]

        # A mapping of scheme to a list of code keywords
        cid_concepts: dict[str, list[str]] = {}
        for group in data["compose"]["include"]:
            system = group["system"]
            try:
                scheme_designator = FHIR_SYSTEM_TO_DICOM_SCHEME_DESIGNATOR[system]
            except KeyError:
                raise NotImplementedError(
                    "The DICOM scheme designator for the following FHIR system "
                    f"has not been specified: {system}"
                )
            if scheme_designator not in concepts:
                concepts[scheme_designator] = {}

            for concept in group["concept"]:
                print(concept, concept["code"], concept["display"])
                code_keyword = keyword_from_meaning(concept["display"])
                code = concept["code"].strip()
                display = concept["display"].strip()

                # If new code_keyword under this scheme, start dict of codes/cids that use that code
                if code_keyword not in concepts[scheme_designator]:
                    concepts[scheme_designator][code_keyword] = {code: (display, [cid])}
                else:
                    prior = concepts[scheme_designator][code_keyword]
                    if code in prior:
                        prior[code][1].append(cid)
                    else:
                        prior[code] = (display, [cid])

                    if prior[code][0].lower() != display.lower():
                        # Meanings can only be different by symbols, etc.
                        #    because converted to same keyword.
                        #    Nevertheless, print as info
                        LOGGER.info(
                            f"'{code_keyword}': Meaning '{display}' in CID{cid}, previously "
                            f"'{prior[code][0]}' in CIDs {prior[code][1]}"
                        )

                # Keep track of this cid referencing that code_keyword
                if scheme_designator not in cid_concepts:
                    cid_concepts[scheme_designator] = []

                if code_keyword in cid_concepts[scheme_designator]:
                    LOGGER.warning(
                        f"'{code_keyword}': Meaning '{concept["display"]}' in CID{cid} is "
                        "duplicated!"
                    )

                cid_concepts[scheme_designator].append(code_keyword)

        cid_lists[cid] = cid_concepts

    scheme_designator = "SCT"
    # snomed_codes = get_table_o1()
    for code, srt_code, meaning in snomed_mapping:
        name = keyword_from_meaning(meaning)
        if name not in concepts[scheme_designator]:
            concepts[scheme_designator][name] = {code: (meaning, [])}
        else:
            prior = concepts[scheme_designator][name]
            if code not in prior:
                prior[code] = (meaning, [])

    scheme_designator = "DCM"
    for code, meaning in dicom_mapping:
        name = keyword_from_meaning(meaning)
        if name not in concepts[scheme_designator]:
            concepts[scheme_designator][name] = {code: (meaning, [])}
        else:
            prior = concepts[scheme_designator][name]
            if code not in prior:
                prior[code] = (meaning, [])

    write_concepts(concepts, cid_lists, name_for_cid)
    write_snomed_mapping(snomed_mapping)


if __name__ == "__main__":

    args = setup_argparse()
    setup_logger(args.debug)

    path = Path(args.path).resolve()
    if not path.exists():
        path.mkdir(parents=True, exist_ok=True)
    elif not path.is_dir():
        raise ValueError("'path' must be a path to a directory")

    if args.download:
        # Download the ZIP file containing the JSON data
        LOGGER.info(f"Downloading CID files to {path / args.cid_directory}")
        version = download_fhir_value_sets(path)
        if version:
            extract_cid_files(path, version, args.cid_directory)
        else:
            LOGGER.error(f"Failed to download the CID files")

        snomed_data = urllib_request.urlopen(P16_TO1_URL).read()
        dicom_data = urllib_request.urlopen(P16_TD1_URL).read()
    elif args.version:
        # Use the already downloaded ZIP file
        extract_cid_files(path, args.version, args.cid_directory)
        # Parse the already downloaded HTM files
        dicom_data, snomed_data = extract_table_data(path, args.version)

    snomed_mapping = get_table_o1(snomed_data)
    dicom_mapping = get_table_d1(dicom_data)
    process_files(path / args.cid_directory, snomed_mapping, dicom_mapping)
